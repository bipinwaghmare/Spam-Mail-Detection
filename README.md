# ğŸ“§ Spam Mail Detection Project

## ğŸ“Œ Overview

This repository contains three distinct implementations of a **Spam Mail Detection System**, showcasing different levels of complexity and technology. The implementations include:  
1. ğŸ·ï¸ **Simple Machine Learning Approach**  
2. ğŸ­ **Spam Detection with NLTK & Bernoulli Naive Bayes** deployed using **Streamlit**  
3. ğŸš€ **Advanced Classification using BERT** for state-of-the-art performance  

Each implementation is in a separate folder with its own `README.md` file containing detailed information.

---

## ğŸ“‚ Project Structure

```plaintext
ğŸ“‚ spam-mail-detection/
â”‚
â”œâ”€â”€ ğŸ“‚ simple-way/
â”‚   â””â”€â”€ ğŸ“„ README.md  # Simple Machine Learning implementation
â”‚
â”œâ”€â”€ ğŸ“‚ streamlit-nltk/
â”‚   â””â”€â”€ ğŸ“„ README.md  # Naive Bayes implementation with Streamlit deployment
â”‚
â”œâ”€â”€ ğŸ“‚ bert-implementation/
â”‚   â””â”€â”€ ğŸ“„ README.md  # BERT-based advanced classification
â”‚
â””â”€â”€ ğŸ“„ README.md      # This file
```

---

## ğŸ” Implementation Details

### 1ï¸âƒ£ Simple Machine Learning Approach
- **ğŸ“ Folder**: `simple-way/`
- **ğŸ› ï¸ Key Features**:
  - Utilizes **CountVectorizer** for text vectorization.
  - Handles class imbalance with **SMOTE**.
  - Models used: Logistic Regression and Random Forest.
- **ğŸ“Š Performance**:
  - High accuracy (~99%) and balanced precision/recall for both spam and ham messages.
- **âœ… Best For**: Quick implementation with minimal resource usage.

---

### 2ï¸âƒ£ Spam Detection with Naive Bayes and Streamlit
- **ğŸ“ Folder**: `streamlit-nltk/`
- **ğŸ› ï¸ Key Features**:
  - Preprocessing with **NLTK** (tokenization, stopword removal, stemming).
  - **TF-IDF** vectorization for feature extraction.
  - Deploys a **Streamlit Web App** for interactive predictions.
- **ğŸ“Š Performance**:
  - **Bernoulli Naive Bayes** achieved ~99% accuracy.
- **âœ… Best For**: Interactive and user-friendly web application.

---

### 3ï¸âƒ£ Advanced Email Classification using BERT
- **ğŸ“ Folder**: `bert-implementation/`
- **ğŸ› ï¸ Key Features**:
  - Implements **BERT** for robust feature extraction and classification.
  - Fine-tuned on a spam email dataset.
  - Designed for execution in **Google Colab** with GPU acceleration.
- **ğŸ“Š Performance**:
  - Achieved ~99% accuracy with excellent recall and precision.
- **âœ… Best For**: Advanced applications requiring high accuracy and state-of-the-art NLP.

---

## ğŸš€ How to Use This Repository

### ğŸ› ï¸ Prerequisites
1. ğŸ Python 3.8+ installed.
2. ğŸ“¦ Necessary libraries installed (`pip install -r requirements.txt` for each implementation).

### ğŸ”„ Steps:
1. Navigate to the desired folder (`simple-way/`, `streamlit-nltk/`, or `bert-implementation/`).
2. Follow the instructions in the respective `README.md` file to run the implementation.

---

## ğŸ“Š Comparison of Approaches

| âš¡ Approach                 | ğŸ”¬ Technique              | ğŸŒ Deployment  | ğŸ¯ Accuracy | ğŸ“Œ Best Use Case                            |
|----------------------------|---------------------------|---------------|------------|---------------------------------------------|
| **Simple ML Approach**      | CountVectorizer + SMOTE  | Notebook      | 99%        | Basic implementation with minimal setup.    |
| **Streamlit + Naive Bayes** | TF-IDF + Bernoulli NB    | Streamlit Web | 99%        | User-friendly, interactive web application. |
| **BERT Implementation**     | Transformer (BERT)       | Google Colab  | 99%        | Advanced use cases with state-of-the-art NLP. |

---

## ğŸ‘¥ Contributors

- **Bipin Waghmare**  
  - ğŸ”— [LinkedIn](https://www.linkedin.com/in/bipin-waghmare-2bb623167/)  
  - ğŸ™ [GitHub](https://github.com/bipinwaghmare)

---

## ğŸ“œ License

This project is licensed under the [MIT License](https://opensource.org/licenses/MIT).

---

## ğŸ™Œ Acknowledgments

Special thanks to:
- ğŸ§  **Scikit-learn**, **NLTK**, and **Transformers** teams for providing essential libraries.
- ğŸŒ **Streamlit** for simplifying web app deployment.
- ğŸ“Š The open-source community for datasets and resources.

